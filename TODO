get buffer reference out of HTTPMessage.   Put it directly in HTTP request and response and let them pass it down to the parsers.  Or just put it in the parsers.  And make sure the parsers have initialization checks for it.

swapping rule (from recv to send):  swap iff send is empty and recv has no data from the next transaction in it.  Else copy

buffer rework:
 - http client and http server sockets should each have their own iobuffer (for http/1.1 the same iobuffer can be used for both requests and responses), but should be bufferless between transactions on the socket.
 - parse buffers should be stored in the transaction and can be shared by request and response parsers since those too are not concurrently active
 - connection pool can just store inactive client sockets, assuming their footprint can be kept small.
 
 - tldr - all buffers could live in server and client transactions!  both server and client sockets store ptrs to their active transaction.
 - sever socket factory
 - client socket factory
 - server transaction factory:  embeds buffers
 - client transaction factory:  embeds buffers

Should placement new automatically set cleanup handler... put cleanup handler in ESB::Object

consider creating page allocator using mmap and using this in ESHttpMultiplexerImpl
Move state from sockets to transactions
use nullptr.  If not define, define nullptr to 0.

add noexcept to all uses of placement new
use allocator cleanup handlers in embedded list test and more widely
is there a way to ensure that server transactions always live longer than their associated client transactions?
log statements that pretty print peer address
pause/resume for http server sockets
pause/resume for http client sockets
pause/resome for http listening sockets (overloaded use case)
http client socket should store HttpServerTransaction _transaction
make http client socket reuse server socket's discard allocator, when there is a server socket
let http client sockets resume http server sockets and vice versa

discard allocators should round up to nearest page size

           #include <unistd.h>
           long sz = sysconf(_SC_PAGESIZE);

multiplex socket
 - SO_REUSE_PORT
 - consider not exposing isRunning to impls... they should be returning asap anyways
 - each multiplexer allocs array of max fd epoll events.  instead divide max fds by num multiplexers
http stack test
 - acquire proxy test:  proxy callbacks + route API
 - support many hostnames in client server tests so we can exercise more ports.  Current max tested is 25k client -> 25k server.
 - make sure failover allocators are sufficiently tested or remove them
 - flakey http1 parser test
 - bind to ephemeral port in stack unit tests
 - why was std::bad_alloc thrown by http client/server test?  verify -fno-exceptions.  check leaks
 - pin threads / fe-be connection alignment
proxy main
 - start as root, bind to ports, drop privs
 - load shedding
 - support PAUSE returns from HttpServerHandler::acceptConnection
 - readiness and liveness check support - e2e vs local options
 - plugin api
multiplexer dispatcher
 - helpful or harmful?  better to allow unbalance and just let each multipler add whatever it accepts?
 - dispatch to multiplexer with silo affinity/be-fe connection alignment?
allocators
 - add ctrs for discard allocator to track extra large chunk allocations
 - add counters to track stranded memory in discard allocators
 - replace all allocators with system allocator and compare with and without libtcmalloc
containers
 - fix multimap or replace with stl
 - lockless datastructures - list.  hashmap.
sockets
 - ipv6 support
 - tls support via boringssl
 - ktls sockmap and splice
cmake
 - finish todos in config.cmake - a few adhoc test programs
 - doxygen
 - code coverage
 - addr space randomization
docs
 - fix license - 3 levels of derivation
async dns client
 - start with caching sync impl and async interface.  cache according to the dns record ttl and LRU
 - common caching code.  intial async impl can use threadpool and gethostbyname
tcp stuff
 - make sure full duplex
 - track bps
 - turn into a unit test over loopback/same proc
http stuff
 - idle timeout
 - max requests per connection option (1 disables keepalives)
 - max header size option
 - max body size option
 - save don't skip trailer
 - slow loris defense
 - https support
 - h2 support
 - perfect forward secrecy
 - sni-based cert serving
 - tls staples
 - support 100 Continue
 - support max requests per connection
 - support receiving half closed from client while still sending outstanding response
 - make all the unsigned chars in HttpMessage, HttpRequest, and HttpReponse chars?  UTF-8 only in encoded form?
URL 
 - canonicalization / encode and decode per chromium RFC
 - username and pass
 - fully parse query string
bootstrap config
 - reload when file changes or on SIGHUP.  ports, buffer sizes, etc
 - xds agent could just regenerate this, serializing updates and using atomic moves
 - could potentially break into multiple files for scalability, but then need cross-file atomic update mechanism.
 - journalling approach?  base bootstrap file.  log of incremental updates.   compress incremental updates to avoid filling disk
xds support
 - protobuf stubs
logging
 - rotating file logger - batch into memory buffers and flush occasionally.  double buffer.  fill one while flush other.  if one to be filled is too small, drop messages
perf counters
 - calc percentiles in latency - https://www.codeproject.com/Articles/25656/Calculating-Percentiles-in-Memory-bound-Applicatio
